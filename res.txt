+ umask 007
+ NGPU=4
+ MASTER_PORT=29501
+ PORT=1106
+ LOG_RANK=0
+ TORCHFT_LIGHTHOUSE=http://localhost:29510
+ CONFIG_NAME=robotwin_trajectory_train
+ overrides=
+ '[' 0 -ne 0 ']'
+ export WANDB_MODE=offline
+ WANDB_MODE=offline
+ export WANDB_API_KEY=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
+ WANDB_API_KEY=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
+ export WANDB_BASE_URL=https://api.wandb.ai
+ WANDB_BASE_URL=https://api.wandb.ai
+ export WANDB_TEAM_NAME=VictorIPRN
+ WANDB_TEAM_NAME=VictorIPRN
+ export WANDB_PROJECT=Lingbot_traj
+ WANDB_PROJECT=Lingbot_traj
+ num_gpu=4
+ master_port=29501
+ log_rank=0
+ torchft_lighthouse=http://localhost:29510
+ config_name=robotwin_trajectory_train
+ export TOKENIZERS_PARALLELISM=false
+ TOKENIZERS_PARALLELISM=false
+ PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ TORCHFT_LIGHTHOUSE=http://localhost:29510
+ python -m torch.distributed.run --nproc_per_node=4 --local-ranks-filter=0 --master_port 29501 --tee 3 -m wan_va.train_trajectory --config-name robotwin_trajectory_train

*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[default0]:2026-02-22 23:19:00,910 - root - INFO - Using config: robotwin_trajectory_train
[default0]:2026-02-22 23:19:00,911 - root - INFO - H5 dataset path: /mnt/public/data/h200/victor/mshab/replica/scene_datasets/replica_cad_dataset/rearrange-dataset/prepare_groceries/pick/002_master_chef_can.h5
[default0]:2026-02-22 23:19:00,911 - root - INFO - World size: 4, Local rank: 0
[default0]:wandb: WARNING Unable to verify login in offline mode.
[default0]:wandb: Tracking run with wandb version 0.25.0
[default0]:wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[default0]:wandb: Run data is saved locally in /mnt/public/data/h200/victor/lingbot-va/wandb/offline-run-20260222_231900-l6szr1wk
[default0]:2026-02-22 23:19:01,711 - root - INFO - WandB logging enabled
[default0]:2026-02-22 23:19:01,711 - root - INFO - Loading transformer...
[default0]:The config attributes {'added_kv_proj_dim': None, 'image_dim': None, 'qk_norm': 'rms_norm_across_heads'} were passed to WanTransformer3DModel, but are not expected and will be ignored. Please verify your config.json configuration file.
[default0]:
[default0]:Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s][default0]:
[default0]:Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:05<00:11,  5.90s/it][default0]:
[default0]:Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:11<00:05,  5.84s/it][default0]:
[default0]:Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  3.43s/it]
[default0]:Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.09s/it]
[default0]:Some weights of the model checkpoint at /mnt/public/data/h200/victor/lingbot-va/checkpoints/lingbot-va-base/transformer were not used when initializing WanTransformer3DModel: 
[default0]: ['patch_embedding.weight, patch_embedding.bias']
[default0]:2026-02-22 23:19:14,019 - root - INFO - Setting up activation checkpointing ...
[default0]:2026-02-22 23:19:14,020 - root - INFO - Setting up FSDP...
[default0]:/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[default0]:  warnings.warn(  # warn only once
[default0]:[rank0]:[W222 23:19:14.098602085 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[default0]:2026-02-22 23:19:22,051 - root - INFO - Setting up trajectory dataset (H5)...
[default0]:2026-02-22 23:19:25,015 - root - INFO - Starting trajectory training...
[default0]:
[default0]:Training (trajectory):   0%|          | 0/42250 [00:00<?, ?it/s][default0]:Traceback (most recent call last):
[default0]:  File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[default0]:    return _run_code(code, main_globals, None,
[default0]:  File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/runpy.py", line 86, in _run_code
[default0]:    exec(code, run_globals)
[default0]:  File "/mnt/public/data/h200/victor/lingbot-va/wan_va/train_trajectory.py", line 457, in <module>
[default0]:    main()
[default0]:  File "/mnt/public/data/h200/victor/lingbot-va/wan_va/train_trajectory.py", line 452, in main
[default0]:    run(args)
[default0]:  File "/mnt/public/data/h200/victor/lingbot-va/wan_va/train_trajectory.py", line 438, in run
[default0]:    trainer.train()
[default0]:  File "/mnt/public/data/h200/victor/lingbot-va/wan_va/train_trajectory.py", line 410, in train
[default0]:    self.train_epoch()
[default0]:  File "/mnt/public/data/h200/victor/lingbot-va/wan_va/train_trajectory.py", line 308, in train_epoch
[default0]:    input_dict = self._prepare_input_dict(batch)
[default0]:  File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[default0]:    return func(*args, **kwargs)
[default0]:  File "/mnt/public/data/h200/victor/lingbot-va/wan_va/train_trajectory.py", line 206, in _prepare_input_dict
[default0]:    latent_dict = self._add_noise(
[default0]:  File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[default0]:    return func(*args, **kwargs)
[default0]:  File "/mnt/public/data/h200/victor/lingbot-va/wan_va/train_trajectory.py", line 153, in _add_noise
[default0]:    B, C, F, H, W = latent.shape
[default0]:ValueError: too many values to unpack (expected 5)
[default0]:[rank0]: Traceback (most recent call last):
[default0]:[rank0]:   File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[default0]:[rank0]:     return _run_code(code, main_globals, None,
[default0]:[rank0]:   File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/runpy.py", line 86, in _run_code
[default0]:[rank0]:     exec(code, run_globals)
[default0]:[rank0]:   File "/mnt/public/data/h200/victor/lingbot-va/wan_va/train_trajectory.py", line 457, in <module>
[default0]:[rank0]:     main()
[default0]:[rank0]:   File "/mnt/public/data/h200/victor/lingbot-va/wan_va/train_trajectory.py", line 452, in main
[default0]:[rank0]:     run(args)
[default0]:[rank0]:   File "/mnt/public/data/h200/victor/lingbot-va/wan_va/train_trajectory.py", line 438, in run
[default0]:[rank0]:     trainer.train()
[default0]:[rank0]:   File "/mnt/public/data/h200/victor/lingbot-va/wan_va/train_trajectory.py", line 410, in train
[default0]:[rank0]:     self.train_epoch()
[default0]:[rank0]:   File "/mnt/public/data/h200/victor/lingbot-va/wan_va/train_trajectory.py", line 308, in train_epoch
[default0]:[rank0]:     input_dict = self._prepare_input_dict(batch)
[default0]:[rank0]:   File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[default0]:[rank0]:     return func(*args, **kwargs)
[default0]:[rank0]:   File "/mnt/public/data/h200/victor/lingbot-va/wan_va/train_trajectory.py", line 206, in _prepare_input_dict
[default0]:[rank0]:     latent_dict = self._add_noise(
[default0]:[rank0]:   File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[default0]:[rank0]:     return func(*args, **kwargs)
[default0]:[rank0]:   File "/mnt/public/data/h200/victor/lingbot-va/wan_va/train_trajectory.py", line 153, in _add_noise
[default0]:[rank0]:     B, C, F, H, W = latent.shape
[default0]:[rank0]: ValueError: too many values to unpack (expected 5)
W0222 23:19:27.299000 851176 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 851249 closing signal SIGTERM
W0222 23:19:27.301000 851176 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 851250 closing signal SIGTERM
W0222 23:19:27.301000 851176 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 851251 closing signal SIGTERM
E0222 23:19:28.090000 851176 site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 851248) of binary: /mnt/public/data/h200/.miniconda/envs/lingbot/bin/python
Traceback (most recent call last):
  File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/site-packages/torch/distributed/run.py", line 905, in <module>
    main()
  File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
  File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/mnt/public/data/h200/.miniconda/envs/lingbot/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
wan_va.train_trajectory FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-02-22_23:19:27
  host      : is-dbz2fowdxx3libe3-devmachine-0
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 851248)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[default0]:[1;34mwandb[0m: 
[default0]:[1;34mwandb[0m: You can sync this run to the cloud by running:
[default0]:[1;34mwandb[0m: [1mwandb sync /mnt/public/data/h200/victor/lingbot-va/wandb/offline-run-20260222_231900-l6szr1wk[0m
[default0]:[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20260222_231900-l6szr1wk/logs[0m
